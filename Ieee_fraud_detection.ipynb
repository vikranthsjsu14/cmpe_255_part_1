{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bLia7HFjJdNT",
        "outputId": "6c9f252d-218a-45a5-dfda-b39206a4c815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon)\n",
            "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.multimodal==1.1.1 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\n",
            "Collecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m272.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.1.4)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading boto3-1.35.20-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m802.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m717.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (2.17.0)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.17)\n",
            "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\n",
            "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m828.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (71.0.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.9.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.2)\n",
            "Collecting botocore<1.36.0,>=1.35.20 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading botocore-1.35.20-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.24.7)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.7.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.20.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.60.0)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.5.15)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m908.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\n",
            "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.13.2)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m985.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.16.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (14.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.10.5)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.64.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.8.30)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.1.99)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\n",
            "Collecting pyarrow>=6.0.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.43.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.23.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.3.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.19.2)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (9.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.65.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.24.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.27.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.19.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.6)\n",
            "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.9)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\n",
            "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.20-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
            "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.20-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=de7ef79e99721f708f416df42e1c40b3276e4a988eb1e251e99c8924a4ebb9ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=00c53d64aa33e0fca993fb1befbaa5200dc3a3c9c2693c8494f3550267c5f596\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=b6b02889ba894ea1b5ddd034a5e284111ac832bdcb8a0ddbed9bf79d884b03ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, antlr4-python3-runtime, xxhash, virtualenv, triton, tensorboardX, scipy, PyWavelets, pycryptodome, pyarrow, Pillow, orjson, ordered-set, openxlab, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, lightning-utilities, jmespath, humanfriendly, dill, colorama, xgboost, window-ops, pytesseract, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, lightgbm, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, s3transfer, opendatalab, onnxruntime, nvidia-cusolver-cu12, jsonschema, gluonts, catboost, transformers, torch, statsforecast, ray, openmim, opencensus, nlpaug, mlforecast, boto3, aiohttp-cors, torchvision, torchmetrics, pytorch-metric-learning, datasets, autogluon.common, accelerate, timm, pytorch-lightning, optimum, evaluate, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.1.1\n",
            "    Uninstalling xgboost-2.1.1:\n",
            "      Successfully uninstalled xgboost-2.1.1\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.4.0\n",
            "    Uninstalling lightgbm-4.4.0:\n",
            "      Successfully uninstalled lightgbm-4.4.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.23.2\n",
            "    Uninstalling scikit-image-0.23.2:\n",
            "      Successfully uninstalled scikit-image-0.23.2\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.0+cu121\n",
            "    Uninstalling torchvision-0.19.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.19.0+cu121\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.14 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n",
            "torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.4.0 PyWavelets-1.7.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 boto3-1.35.20 botocore-1.35.20 catboost-1.2.7 colorama-0.4.6 coloredlogs-15.0.1 colorful-0.5.6 datasets-3.0.0 dill-0.3.8 distlib-0.3.8 evaluate-0.4.3 gluonts-0.15.1 humanfriendly-10.0 jmespath-1.0.1 jsonschema-4.21.1 lightgbm-4.3.0 lightning-2.3.3 lightning-utilities-0.11.7 mlforecast-0.10.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.16.2 onnxruntime-1.19.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.7 pdf2image-1.17.0 py-spy-0.3.14 pyarrow-17.0.0 pycryptodome-3.20.0 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 s3transfer-0.10.2 scikit-image-0.20.0 scipy-1.12.0 seqeval-1.2.2 statsforecast-1.4.0 tensorboardX-2.6.2.2 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 virtualenv-20.26.4 window-ops-0.0.15 xgboost-2.0.3 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              },
              "id": "296778c761c04e17ae1fb192f7306625"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install autogluon\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "IPV5p8IvMiEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8WbaPrhMl3t",
        "outputId": "885a0d4e-36fd-47b9-bdda-8d9905a060e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content\n",
            " 76% 90.0M/118M [00:00<00:00, 205MB/s]\n",
            "100% 118M/118M [00:00<00:00, 232MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c ieee-fraud-detection -p /content/IEEEfraud/\n",
        "!unzip /content/IEEEfraud/ieee-fraud-detection.zip -d /content/IEEEfraud/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53DN6PMhMr7P",
        "outputId": "c88823f5-8c00-4feb-a982-ab26a7d6c4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content/IEEEfraud\n",
            " 78% 92.0M/118M [00:00<00:00, 333MB/s]\n",
            "100% 118M/118M [00:00<00:00, 337MB/s] \n",
            "Archive:  /content/IEEEfraud/ieee-fraud-detection.zip\n",
            "  inflating: /content/IEEEfraud/sample_submission.csv  \n",
            "  inflating: /content/IEEEfraud/test_identity.csv  \n",
            "  inflating: /content/IEEEfraud/test_transaction.csv  \n",
            "  inflating: /content/IEEEfraud/train_identity.csv  \n",
            "  inflating: /content/IEEEfraud/train_transaction.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/IEEEfraud/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCZM-uW5Pt66",
        "outputId": "c7c7760c-12fa-45ea-a87e-72f9e7354228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ieee-fraud-detection.zip  test_identity.csv\ttrain_identity.csv\n",
            "sample_submission.csv\t  test_transaction.csv\ttrain_transaction.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "directory = '/content/IEEEfraud/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label = 'isFraud'  # name of target variable to predict in this competition\n",
        "eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n",
        "save_path = directory + 'AutoGluonModels/'  # where to store trained models\n",
        "\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')"
      ],
      "metadata": {
        "id": "LnftQEICM9Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"
      ],
      "metadata": {
        "id": "TTyWPrWQSS19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='best_quality', time_limit=3600\n",
        ")\n",
        "\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf_jRuj5SWuF",
        "outputId": "dd693da8-c885-46d7-a840-3907ed5934c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/IEEEfraud/AutoGluonModels/\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          8\n",
            "GPU Count:          0\n",
            "Memory Avail:       44.22 GB / 50.99 GB (86.7%)\n",
            "Disk Space Avail:   180.38 GB / 225.83 GB (79.9%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True, 'num_bag_sets': 1}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2024-09-17 05:23:58,627\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Beginning AutoGluon training ... Time limit = 895s\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m AutoGluon will save models to \"/content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Train Data Rows:    524924\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Train Data Columns: 433\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Label Column:       isFraud\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tAvailable Memory:                    40823.70 MB\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTrain Data (Original)  Memory Usage: 2278.50 MB (5.6% of available memory)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tWarning: Data size prior to feature transformation consumes 5.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t4.9s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t5.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t0.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t1.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t3.6s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t4 duplicate columns removed: ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t5.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t\t429 features in original data used to generate 429 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tUnused Original Features (Count: 4): ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('float', []) : 4 | ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('float64', 'float') : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('float', [])  : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('float64', 'float')     : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t31.9s = Fit runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t429 features in original data used to generate 429 features in processed data.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTrain Data (Processed) Memory Usage: 1610.46 MB (4.0% of available memory)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Data preprocessing and feature engineering runtime = 38.0s ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting 110 L1 models ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 570.95s of the 856.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.11s \t= Train Time (Using 10000/524924 rows) (569.22s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.19s \t= Train Time (Using 20000/524924 rows) (569.03s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.35s \t= Train Time (Using 40000/524924 rows) (568.68s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.69s \t= Train Time (Using 80000/524924 rows) (567.99s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t1.32s \t= Train Time (Using 160000/524924 rows) (566.68s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2.61s \t= Train Time (Using 320000/524924 rows) (564.07s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.63s \t= Train Time (Using 524924/524924 rows) (563.44s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2729.23s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 2729.23s compared to 731.94s of available time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 553.47s of the 839.15s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.1s \t= Train Time (Using 10000/524924 rows) (551.75s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.16s \t= Train Time (Using 20000/524924 rows) (551.58s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.3s \t= Train Time (Using 40000/524924 rows) (551.28s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.57s \t= Train Time (Using 80000/524924 rows) (550.71s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t1.1s \t= Train Time (Using 160000/524924 rows) (549.61s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2.16s \t= Train Time (Using 320000/524924 rows) (547.45s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.62s \t= Train Time (Using 524924/524924 rows) (546.83s remaining time)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2492.88s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 2492.88s compared to 710.11s of available time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 538.7s of the 824.37s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.49% memory usage per fold, 54.98%/80.00% total).\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=27.49%)\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0937092\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0849441\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0803973\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0772934\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0747857\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0726657\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12120)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0737678\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [400]\tvalid_set's binary_logloss: 0.0696455\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [450]\tvalid_set's binary_logloss: 0.068529\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0674422\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0664215\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12119)\u001b[0m [600]\tvalid_set's binary_logloss: 0.0654624\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0964283\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0920516\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0837352\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [100]\tvalid_set's binary_logloss: 0.087369\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [150]\tvalid_set's binary_logloss: 0.082838\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0792937\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0795921\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0764876\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0770251\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0742695\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0721985\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0750946\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0706245\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0735415\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [400]\tvalid_set's binary_logloss: 0.072224\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [400]\tvalid_set's binary_logloss: 0.0692878\n",
            "\u001b[36m(_ray_fit pid=12681)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0710151\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0680489\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0668289\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0658194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12682)\u001b[0m [600]\tvalid_set's binary_logloss: 0.064872\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0952447\n",
            "\u001b[36m(_ray_fit pid=13244)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0942062\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0868355\n",
            "\u001b[36m(_ray_fit pid=13244)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0852749\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [200]\tvalid_set's binary_logloss: 0.079432\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [250]\tvalid_set's binary_logloss: 0.077055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0748356\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13244)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0748883\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0731141\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [400]\tvalid_set's binary_logloss: 0.0716709\n",
            "\u001b[36m(_ray_fit pid=13244)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0725445\n",
            "\u001b[36m(_ray_fit pid=13244)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0709679\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13243)\u001b[0m [550]\tvalid_set's binary_logloss: 0.0684293\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0953859\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0866871\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0820553\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0788524\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0764795\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0745371\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [350]\tvalid_set's binary_logloss: 0.0728195\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13805)\u001b[0m [400]\tvalid_set's binary_logloss: 0.0713881\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0687941\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m [500]\tvalid_set's binary_logloss: 0.067677\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.9437\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t464.1s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t24.22s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2708.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=13806)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 62.81s of the 348.49s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.71% memory usage per fold, 57.41%/80.00% total).\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=28.71%)\n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=14486)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14667)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=14845)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15023)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.8031\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t80.13s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t1.97s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t33256.6\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForestGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=15024)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 259.12s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.91s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m [1. 0.]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.9437\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t5.84s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.11s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2707.2\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting 108 L2 models ...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 253.14s of the 252.44s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.12% memory usage per fold, 60.23%/80.00% total).\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.12%)\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m   warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0719072\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0669664\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0651479\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15353)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0634197\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=15680)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0758407\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15680)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0709419\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0659704\n",
            "\u001b[36m(_ray_fit pid=15680)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0675039\n",
            "\u001b[36m(_ray_fit pid=15680)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0653919\n",
            "\u001b[36m(_ray_fit pid=15679)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0637785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0749439\n",
            "\u001b[36m(_ray_fit pid=16006)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0753586\n",
            "\u001b[36m(_ray_fit pid=16006)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0692751\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0692873\n",
            "\u001b[36m(_ray_fit pid=16006)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0664481\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0673485\n",
            "\u001b[36m(_ray_fit pid=16006)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0644536\n",
            "\u001b[36m(_ray_fit pid=16005)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0649944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0746839\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0725875\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0681571\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0656252\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0655822\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0629955\n",
            "\u001b[36m(_ray_fit pid=16335)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0635597\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0615282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.9497\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t229.21s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t6.56s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2003.0\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=16336)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 14.6s of the 13.89s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 30.11% memory usage per fold, 60.21%/80.00% total).\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=30.11%)\n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=16786)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16964)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17142)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m This will raise in a future version.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17319)\u001b[0m   warnings.warn(msg, FutureWarning)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.9325\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t79.19s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t1.82s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2341.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_ray_fit pid=17324)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -75.35s of remaining time.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.89s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m [0. 0. 1. 0.]\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.9497\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t11.64s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t0.11s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \t2002.2\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m AutoGluon training complete, total runtime = 986.38s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2002.2 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.1.1\"\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Saving /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m /usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m This will raise in a future version.\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m \n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Loading: /content/IEEEfraud/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=11273)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L2       0.953927   0.949736     roc_auc       22.025671      32.758256  773.431433                 4.950010                6.561420         229.207803            2       True          4\n",
            "1  WeightedEnsemble_L3       0.953927   0.949736     roc_auc       22.028766      32.871497  785.076296                 0.003094                0.113241          11.644863            3       True          6\n",
            "2    LightGBMXT_BAG_L1       0.944436   0.943720     roc_auc       15.209229      24.223814  464.098578                15.209229               24.223814         464.098578            1       True          1\n",
            "3  WeightedEnsemble_L2       0.944436   0.943720     roc_auc       15.212074      24.335109  469.936831                 0.002845                0.111294           5.838253            2       True          3\n",
            "4      LightGBM_BAG_L2       0.935470   0.932484     roc_auc       19.193603      28.020121  623.417209                 2.117942                1.823285          79.193579            2       True          5\n",
            "5      LightGBM_BAG_L1       0.805635   0.803090     roc_auc        1.866432       1.973021   80.125052                 1.866432                1.973021          80.125052            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t1028s\t = DyStack   runtime |\t2572s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Saving /content/IEEEfraud/AutoGluonModels/learner.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 2572s\n",
            "AutoGluon will save models to \"/content/IEEEfraud/AutoGluonModels/\"\n",
            "Train Data Rows:    590540\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    41765.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2590.15 MB (6.2% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 6.2% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t2.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.7s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.1s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.6s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t4.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t5 duplicate columns removed: ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t5.5s = Fit runtime\n",
            "\t\t\t428 features in original data used to generate 428 features in processed data.\n",
            "\tUnused Original Features (Count: 5): ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 5 | ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t26.7s = Fit runtime\n",
            "\t428 features in original data used to generate 428 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1807.27 MB (4.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 31.38s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/IEEEfraud/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}, {'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17}}, {'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19}}, {'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26}}, {'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35}}, {'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38}}, {'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41}}, {'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49}}, {'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52}}, {'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59}}, {'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60}}, {'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65}}, {'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77}}, {'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79}}, {'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84}}, {'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87}}, {'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92}}, {'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96}}, {'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3}}, {'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6}}, {'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14}}, {'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18}}, {'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27}}, {'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31}}, {'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37}}, {'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44}}, {'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48}}, {'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56}}, {'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69}}, {'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74}}, {'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24}}, {'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33}}, {'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50}}, {'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67}}, {'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72}}, {'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76}}, {'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83}}, {'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89}}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}, {'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'name_suffix': '_r194', 'priority': -22}}, {'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'name_suffix': '_r98', 'priority': -36}}, {'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'name_suffix': '_r49', 'priority': -57}}, {'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'name_suffix': '_r31', 'priority': -64}}, {'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'name_suffix': '_r22', 'priority': -70}}, {'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'name_suffix': '_r95', 'priority': -93}}, {'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'name_suffix': '_r34', 'priority': -94}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15}}, {'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21}}, {'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25}}, {'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28}}, {'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30}}, {'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34}}, {'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40}}, {'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46}}, {'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51}}, {'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54}}, {'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55}}, {'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66}}, {'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71}}, {'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73}}, {'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75}}, {'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80}}, {'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82}}, {'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85}}, {'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88}}, {'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13}}, {'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32}}, {'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45}}, {'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47}}, {'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63}}, {'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68}}, {'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9}}, {'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23}}, {'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43}}, {'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53}}, {'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62}}, {'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78}}, {'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Saving /content/IEEEfraud/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/utils/data/y.pkl\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Model configs that will be trained (in order):\n",
            "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "\tCatBoost_r177_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L1: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L1: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L1: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L1: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L1: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L1: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L1: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L1: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L1: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L1: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L1: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L1: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L1: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L1: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L1: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L1: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L1: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L1: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L1: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L1: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L1: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L1: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L1: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L1: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L1: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L1: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L1: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L1: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L1: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L1: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L1: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L1: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L1: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L1: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L1: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L1: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L1: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L1: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1693.25s of the 2540.3s of remaining time.\n",
            "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "\t0.11s \t= Train Time (Using 10000/590540 rows) (1691.32s remaining time)\n",
            "\t0.19s \t= Train Time (Using 20000/590540 rows) (1691.13s remaining time)\n",
            "\t0.33s \t= Train Time (Using 40000/590540 rows) (1690.79s remaining time)\n",
            "\t0.62s \t= Train Time (Using 80000/590540 rows) (1690.17s remaining time)\n",
            "\t1.19s \t= Train Time (Using 160000/590540 rows) (1688.98s remaining time)\n",
            "\t2.34s \t= Train Time (Using 320000/590540 rows) (1686.63s remaining time)\n",
            "\t0.7s \t= Train Time (Using 590540/590540 rows) (1685.94s remaining time)\n",
            "\t4778.7s\t= Estimated out-of-fold prediction time...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 4778.7s compared to 2190.82s of available time.\n",
            "\tTime limit exceeded... Skipping KNeighborsUnif_BAG_L1.\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1675.38s of the 2522.42s of remaining time.\n",
            "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "\t0.16s \t= Train Time (Using 10000/590540 rows) (1673.4s remaining time)\n",
            "\t0.3s \t= Train Time (Using 20000/590540 rows) (1673.1s remaining time)\n",
            "\t0.57s \t= Train Time (Using 40000/590540 rows) (1672.53s remaining time)\n",
            "\t1.4s \t= Train Time (Using 80000/590540 rows) (1671.13s remaining time)\n",
            "\t2.7s \t= Train Time (Using 160000/590540 rows) (1668.43s remaining time)\n",
            "\t4.91s \t= Train Time (Using 320000/590540 rows) (1663.51s remaining time)\n",
            "\t2.53s \t= Train Time (Using 590540/590540 rows) (1660.98s remaining time)\n",
            "\t4785.93s\t= Estimated out-of-fold prediction time...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 4785.93s compared to 2160.55s of available time.\n",
            "\tTime limit exceeded... Skipping KNeighborsDist_BAG_L1.\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1650.53s of the 2497.57s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 34.91% memory usage per fold, 69.83%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=34.91%)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.962\t = Validation score   (roc_auc)\n",
            "\t1380.5s\t = Training   runtime\n",
            "\t73.8s\t = Validation runtime\n",
            "\t1000.3\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 246.5s of the 1093.54s of remaining time.\n",
            "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.99% memory usage per fold, 59.97%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=29.99%)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "\t0.9282\t = Validation score   (roc_auc)\n",
            "\t228.27s\t = Training   runtime\n",
            "\t7.73s\t = Validation runtime\n",
            "\t9548.6\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 7.94s of the 854.98s of remaining time.\n",
            "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\tWarning: Model is expected to require 486.6s to train, which exceeds the maximum time limit of 7.9s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 838.25s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1. 0.]\n",
            "\t0.97s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.962\t = Validation score   (roc_auc)\n",
            "\t6.81s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "\t1000.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "\tCatBoost_r177_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r79_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r131_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7023601671276614, 'learning_rate': 0.012144796373999013, 'min_data_in_leaf': 14, 'num_leaves': 53, 'ag_args': {'name_suffix': '_r131', 'priority': -3, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r191_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r9_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tLightGBM_r96_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5636931414546802, 'learning_rate': 0.01518660230385841, 'min_data_in_leaf': 48, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r96', 'priority': -6, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r22_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r33_BAG_L2: \t{'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r33', 'priority': -8, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r42_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18392, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r42', 'priority': -9, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r137_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.559174625782161, 'learning_rate': 0.04939557741379516, 'max_ctr_complexity': 3, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r137', 'priority': -10, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r102_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r13_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3274013177541373, 'learning_rate': 0.017301189655111057, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r13', 'priority': -12, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r195_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 37308, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r195', 'priority': -13, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r188_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.8282601210460099, 'learning_rate': 0.033929021353492905, 'min_data_in_leaf': 6, 'num_leaves': 127, 'ag_args': {'name_suffix': '_r188', 'priority': -14, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r145_BAG_L2: \t{'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': -15, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r89_BAG_L2: \t{'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r89', 'priority': -16, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r30_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.24622382571353768, 'hidden_size': 159, 'learning_rate': 0.008507536855608535, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.8201539594953562e-06, 'ag_args': {'name_suffix': '_r30', 'priority': -17, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r130_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.6245777099925497, 'learning_rate': 0.04711573688184715, 'min_data_in_leaf': 56, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r130', 'priority': -18, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r86_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.09976801642258049, 'hidden_size': 135, 'learning_rate': 0.001631450730978947, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 3.867683394425807e-05, 'ag_args': {'name_suffix': '_r86', 'priority': -19, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r50_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7018061518087038, 'learning_rate': 0.07092851311746352, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r50', 'priority': -20, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r11_BAG_L2: \t{'bs': 128, 'emb_drop': 0.026897798530914306, 'epochs': 31, 'layers': [800, 400], 'lr': 0.08045277634470181, 'ps': 0.4569532219038436, 'ag_args': {'name_suffix': '_r11', 'priority': -21, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tXGBoost_r194_BAG_L2: \t{'colsample_bytree': 0.9090166528779192, 'enable_categorical': True, 'learning_rate': 0.09290221350439203, 'max_depth': 7, 'min_child_weight': 0.8041986915994078, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r194', 'priority': -22, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tExtraTrees_r172_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 12845, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r172', 'priority': -23, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r69_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.0457098345001241, 'learning_rate': 0.050294288910022224, 'max_ctr_complexity': 5, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r69', 'priority': -24, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r103_BAG_L2: \t{'bs': 256, 'emb_drop': 0.1508701680951814, 'epochs': 46, 'layers': [400, 200], 'lr': 0.08794353125787312, 'ps': 0.19110623090573325, 'ag_args': {'name_suffix': '_r103', 'priority': -25, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r14_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3905837860053583, 'hidden_size': 106, 'learning_rate': 0.0018297905295930797, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 9.178069874232892e-08, 'ag_args': {'name_suffix': '_r14', 'priority': -26, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tLightGBM_r161_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5898927512279213, 'learning_rate': 0.010464516487486093, 'min_data_in_leaf': 11, 'num_leaves': 252, 'ag_args': {'name_suffix': '_r161', 'priority': -27, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r143_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.6239200452002372, 'epochs': 39, 'layers': [200, 100, 50], 'lr': 0.07170321592506483, 'ps': 0.670815151683455, 'ag_args': {'name_suffix': '_r143', 'priority': -28, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r70_BAG_L2: \t{'depth': 6, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.3584121369544215, 'learning_rate': 0.03743901034980473, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r70', 'priority': -29, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r156_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.5055288166864152, 'epochs': 44, 'layers': [400], 'lr': 0.0047762208542912405, 'ps': 0.06572612802222005, 'ag_args': {'name_suffix': '_r156', 'priority': -30, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r196_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.5143401489640409, 'learning_rate': 0.00529479887023554, 'min_data_in_leaf': 6, 'num_leaves': 133, 'ag_args': {'name_suffix': '_r196', 'priority': -31, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r39_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 28310, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r39', 'priority': -32, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tCatBoost_r167_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.522712492188319, 'learning_rate': 0.08481607830570326, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r167', 'priority': -33, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r95_BAG_L2: \t{'bs': 128, 'emb_drop': 0.6656668277387758, 'epochs': 32, 'layers': [400, 200, 100], 'lr': 0.019326244622675428, 'ps': 0.04084945128641206, 'ag_args': {'name_suffix': '_r95', 'priority': -34, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r41_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.05488816803887784, 'hidden_size': 32, 'learning_rate': 0.0075612897834015985, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.652353009917866e-08, 'ag_args': {'name_suffix': '_r41', 'priority': -35, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r98_BAG_L2: \t{'colsample_bytree': 0.516652313273348, 'enable_categorical': True, 'learning_rate': 0.007158072983547058, 'max_depth': 9, 'min_child_weight': 0.8567068904025429, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r98', 'priority': -36, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r15_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.7421180622507277, 'learning_rate': 0.018603888565740096, 'min_data_in_leaf': 6, 'num_leaves': 22, 'ag_args': {'name_suffix': '_r15', 'priority': -37, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r158_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.01030258381183309, 'hidden_size': 111, 'learning_rate': 0.01845979186513771, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 0.00020238017476912164, 'ag_args': {'name_suffix': '_r158', 'priority': -38, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r86_BAG_L2: \t{'depth': 8, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6376578537958237, 'learning_rate': 0.032899230324940465, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r86', 'priority': -39, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r37_BAG_L2: \t{'bs': 512, 'emb_drop': 0.1567472816422661, 'epochs': 41, 'layers': [400, 200, 100], 'lr': 0.06831450078222204, 'ps': 0.4930900813464729, 'ag_args': {'name_suffix': '_r37', 'priority': -40, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r197_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.18109219857068798, 'hidden_size': 250, 'learning_rate': 0.00634181748507711, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 5.3861175580695396e-08, 'ag_args': {'name_suffix': '_r197', 'priority': -41, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r49_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.353268454214423, 'learning_rate': 0.06028218319511302, 'max_ctr_complexity': 1, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r49', 'priority': -42, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r49_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 28532, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r49', 'priority': -43, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r143_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.9408897917880529, 'learning_rate': 0.01343464462043561, 'min_data_in_leaf': 21, 'num_leaves': 178, 'ag_args': {'name_suffix': '_r143', 'priority': -44, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tRandomForest_r127_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 38572, 'min_samples_leaf': 5, 'ag_args': {'name_suffix': '_r127', 'priority': -45, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r134_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.006251885504130949, 'epochs': 47, 'layers': [800, 400], 'lr': 0.01329622020483052, 'ps': 0.2677080696008348, 'ag_args': {'name_suffix': '_r134', 'priority': -46, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r34_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 18242, 'min_samples_leaf': 40, 'ag_args': {'name_suffix': '_r34', 'priority': -47, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r94_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4341088458599442, 'learning_rate': 0.04034449862560467, 'min_data_in_leaf': 33, 'num_leaves': 16, 'ag_args': {'name_suffix': '_r94', 'priority': -48, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r143_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.1703783780377607, 'hidden_size': 212, 'learning_rate': 0.0004107199833213839, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 1.105439140660822e-07, 'ag_args': {'name_suffix': '_r143', 'priority': -49, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r128_BAG_L2: \t{'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.640921865280573, 'learning_rate': 0.036232951900213306, 'max_ctr_complexity': 3, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r128', 'priority': -50, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r111_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6343202884164582, 'epochs': 21, 'layers': [400, 200], 'lr': 0.08479209380262258, 'ps': 0.48362560779595565, 'ag_args': {'name_suffix': '_r111', 'priority': -51, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r31_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.013288954106470907, 'hidden_size': 81, 'learning_rate': 0.005340914647396154, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 8.762168370775353e-05, 'ag_args': {'name_suffix': '_r31', 'priority': -52, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r4_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 19935, 'min_samples_leaf': 20, 'ag_args': {'name_suffix': '_r4', 'priority': -53, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r65_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.22771721361129746, 'epochs': 38, 'layers': [400], 'lr': 0.0005383511954451698, 'ps': 0.3734259772256502, 'ag_args': {'name_suffix': '_r65', 'priority': -54, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetFastAI_r88_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.4329361816589235, 'epochs': 50, 'layers': [400], 'lr': 0.09501311551121323, 'ps': 0.2863378667611431, 'ag_args': {'name_suffix': '_r88', 'priority': -55, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r30_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.9773131270704629, 'learning_rate': 0.010534290864227067, 'min_data_in_leaf': 21, 'num_leaves': 111, 'ag_args': {'name_suffix': '_r30', 'priority': -56, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r49_BAG_L2: \t{'colsample_bytree': 0.7452294043087835, 'enable_categorical': False, 'learning_rate': 0.038404229910104046, 'max_depth': 7, 'min_child_weight': 0.5564183327139662, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r49', 'priority': -57, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tCatBoost_r5_BAG_L2: \t{'depth': 4, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.894432181094842, 'learning_rate': 0.055078095725390575, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r5', 'priority': -58, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r87_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.36669080773207274, 'hidden_size': 95, 'learning_rate': 0.015280159186761077, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.3082489374636015e-08, 'ag_args': {'name_suffix': '_r87', 'priority': -59, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r71_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.3027114570947557, 'hidden_size': 196, 'learning_rate': 0.006482759295309238, 'num_layers': 1, 'use_batchnorm': False, 'weight_decay': 1.2806509958776e-12, 'ag_args': {'name_suffix': '_r71', 'priority': -60, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tCatBoost_r143_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 1.6761016245166451, 'learning_rate': 0.06566144806528762, 'max_ctr_complexity': 2, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r143', 'priority': -61, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tExtraTrees_r178_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 29813, 'min_samples_leaf': 4, 'ag_args': {'name_suffix': '_r178', 'priority': -62, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tRandomForest_r166_BAG_L2: \t{'max_features': 'log2', 'max_leaf_nodes': 42644, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r166', 'priority': -63, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tXGBoost_r31_BAG_L2: \t{'colsample_bytree': 0.7506621909633511, 'enable_categorical': False, 'learning_rate': 0.009974712407899168, 'max_depth': 4, 'min_child_weight': 0.9238550485581797, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r31', 'priority': -64, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetTorch_r185_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.12166942295569863, 'hidden_size': 151, 'learning_rate': 0.0018866871631794007, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 9.190843763153802e-05, 'ag_args': {'name_suffix': '_r185', 'priority': -65, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r160_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3171659718142149, 'epochs': 20, 'layers': [400, 200, 100], 'lr': 0.03087210106068273, 'ps': 0.5909644730871169, 'ag_args': {'name_suffix': '_r160', 'priority': -66, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r60_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.3217885487525205, 'learning_rate': 0.05291587380674719, 'max_ctr_complexity': 5, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r60', 'priority': -67, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tRandomForest_r15_BAG_L2: \t{'max_features': 0.75, 'max_leaf_nodes': 36230, 'min_samples_leaf': 3, 'ag_args': {'name_suffix': '_r15', 'priority': -68, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tLightGBM_r135_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.8254432681390782, 'learning_rate': 0.031251656439648626, 'min_data_in_leaf': 50, 'num_leaves': 210, 'ag_args': {'name_suffix': '_r135', 'priority': -69, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tXGBoost_r22_BAG_L2: \t{'colsample_bytree': 0.6326947454697227, 'enable_categorical': False, 'learning_rate': 0.07792091886639502, 'max_depth': 6, 'min_child_weight': 1.0759464955561793, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r22', 'priority': -70, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tNeuralNetFastAI_r69_BAG_L2: \t{'bs': 128, 'emb_drop': 0.3209601865656554, 'epochs': 21, 'layers': [200, 100, 50], 'lr': 0.019935403046870463, 'ps': 0.19846319260751663, 'ag_args': {'name_suffix': '_r69', 'priority': -71, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r6_BAG_L2: \t{'depth': 4, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 1.5734131496361856, 'learning_rate': 0.08472519974533015, 'max_ctr_complexity': 3, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r6', 'priority': -72, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r138_BAG_L2: \t{'bs': 128, 'emb_drop': 0.08669109226243704, 'epochs': 45, 'layers': [800, 400], 'lr': 0.0041554361714983635, 'ps': 0.2669780074016213, 'ag_args': {'name_suffix': '_r138', 'priority': -73, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tLightGBM_r121_BAG_L2: \t{'extra_trees': False, 'feature_fraction': 0.5730390983988963, 'learning_rate': 0.010305352949119608, 'min_data_in_leaf': 10, 'num_leaves': 215, 'ag_args': {'name_suffix': '_r121', 'priority': -74, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetFastAI_r172_BAG_L2: \t{'bs': 512, 'emb_drop': 0.05604276533830355, 'epochs': 32, 'layers': [400], 'lr': 0.027320709383189166, 'ps': 0.022591301744255762, 'ag_args': {'name_suffix': '_r172', 'priority': -75, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r180_BAG_L2: \t{'depth': 7, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 4.43335055453705, 'learning_rate': 0.055406199833457785, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r180', 'priority': -76, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r76_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.006531401073483156, 'hidden_size': 192, 'learning_rate': 0.012418052210914356, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 3.0406866089493607e-05, 'ag_args': {'name_suffix': '_r76', 'priority': -77, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tExtraTrees_r197_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 40459, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r197', 'priority': -78, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r121_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33926015213879396, 'hidden_size': 247, 'learning_rate': 0.0029983839090226075, 'num_layers': 5, 'use_batchnorm': False, 'weight_decay': 0.00038926240517691234, 'ag_args': {'name_suffix': '_r121', 'priority': -79, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r127_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.31956392388385874, 'epochs': 25, 'layers': [200, 100], 'lr': 0.08552736732040143, 'ps': 0.0934076022219228, 'ag_args': {'name_suffix': '_r127', 'priority': -80, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tRandomForest_r16_BAG_L2: \t{'max_features': 1.0, 'max_leaf_nodes': 48136, 'min_samples_leaf': 1, 'ag_args': {'name_suffix': '_r16', 'priority': -81, 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetFastAI_r194_BAG_L2: \t{'bs': 256, 'emb_drop': 0.5117456464220826, 'epochs': 21, 'layers': [400, 200, 100], 'lr': 0.007212882302137526, 'ps': 0.2747013981281539, 'ag_args': {'name_suffix': '_r194', 'priority': -82, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r12_BAG_L2: \t{'depth': 7, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 4.835797074498082, 'learning_rate': 0.03534026385152556, 'max_ctr_complexity': 5, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r12', 'priority': -83, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetTorch_r135_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.06134755114373829, 'hidden_size': 144, 'learning_rate': 0.005834535148903801, 'num_layers': 5, 'use_batchnorm': True, 'weight_decay': 2.0826540090463355e-09, 'ag_args': {'name_suffix': '_r135', 'priority': -84, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r4_BAG_L2: \t{'bs': 256, 'emb_drop': 0.06099050979107849, 'epochs': 39, 'layers': [200], 'lr': 0.04119582873110387, 'ps': 0.5447097256648953, 'ag_args': {'name_suffix': '_r4', 'priority': -85, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tExtraTrees_r126_BAG_L2: \t{'max_features': 'sqrt', 'max_leaf_nodes': 29702, 'min_samples_leaf': 2, 'ag_args': {'name_suffix': '_r126', 'priority': -86, 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
            "\tNeuralNetTorch_r36_BAG_L2: \t{'activation': 'elu', 'dropout_prob': 0.3457125770744979, 'hidden_size': 37, 'learning_rate': 0.006435774191713849, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 2.4012185204155345e-08, 'ag_args': {'name_suffix': '_r36', 'priority': -87, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetFastAI_r100_BAG_L2: \t{'bs': 2048, 'emb_drop': 0.6960805527533755, 'epochs': 38, 'layers': [800, 400], 'lr': 0.0007278526871749883, 'ps': 0.20495582200836318, 'ag_args': {'name_suffix': '_r100', 'priority': -88, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tCatBoost_r163_BAG_L2: \t{'depth': 5, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.7454481983750014, 'learning_rate': 0.09328642499990342, 'max_ctr_complexity': 1, 'one_hot_max_size': 2, 'ag_args': {'name_suffix': '_r163', 'priority': -89, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tCatBoost_r198_BAG_L2: \t{'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 3.637071465711953, 'learning_rate': 0.04387418552563314, 'max_ctr_complexity': 4, 'one_hot_max_size': 5, 'ag_args': {'name_suffix': '_r198', 'priority': -90, 'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>}}\n",
            "\tNeuralNetFastAI_r187_BAG_L2: \t{'bs': 1024, 'emb_drop': 0.5074958658302495, 'epochs': 42, 'layers': [200, 100, 50], 'lr': 0.026342427824862867, 'ps': 0.34814978753283593, 'ag_args': {'name_suffix': '_r187', 'priority': -91, 'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>}}\n",
            "\tNeuralNetTorch_r19_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.2211285919550286, 'hidden_size': 196, 'learning_rate': 0.011307978270179143, 'num_layers': 1, 'use_batchnorm': True, 'weight_decay': 1.8441764217351068e-06, 'ag_args': {'name_suffix': '_r19', 'priority': -92, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tXGBoost_r95_BAG_L2: \t{'colsample_bytree': 0.975937238416368, 'enable_categorical': False, 'learning_rate': 0.06634196266155237, 'max_depth': 5, 'min_child_weight': 1.4088437184127383, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r95', 'priority': -93, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tXGBoost_r34_BAG_L2: \t{'colsample_bytree': 0.546186944730449, 'enable_categorical': False, 'learning_rate': 0.029357102578825213, 'max_depth': 10, 'min_child_weight': 1.1532008198571337, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'name_suffix': '_r34', 'priority': -94, 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>}}\n",
            "\tLightGBM_r42_BAG_L2: \t{'extra_trees': True, 'feature_fraction': 0.4601361323873807, 'learning_rate': 0.07856777698860955, 'min_data_in_leaf': 12, 'num_leaves': 198, 'ag_args': {'name_suffix': '_r42', 'priority': -95, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
            "\tNeuralNetTorch_r1_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.23713784729000734, 'hidden_size': 200, 'learning_rate': 0.00311256170909018, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 4.573016756474468e-08, 'ag_args': {'name_suffix': '_r1', 'priority': -96, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "\tNeuralNetTorch_r89_BAG_L2: \t{'activation': 'relu', 'dropout_prob': 0.33567564890346097, 'hidden_size': 245, 'learning_rate': 0.006746560197328548, 'num_layers': 3, 'use_batchnorm': True, 'weight_decay': 1.6470047305392933e-10, 'ag_args': {'name_suffix': '_r89', 'priority': -97, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>}}\n",
            "Fitting 108 L2 models ...\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 831.24s of the 830.18s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 31.65% memory usage per fold, 63.29%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=31.65%)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\t0.9668\t = Validation score   (roc_auc)\n",
            "\t706.8s\t = Training   runtime\n",
            "\t38.09s\t = Validation runtime\n",
            "\t617.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 109.67s of the 108.61s of remaining time.\n",
            "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 31.64% memory usage per fold, 63.27%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=31.64%)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "\t0.962\t = Validation score   (roc_auc)\n",
            "\t114.0s\t = Training   runtime\n",
            "\t2.53s\t = Validation runtime\n",
            "\t878.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForestEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r177_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r79_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r131_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r191_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r9_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r96_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r33_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r137_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r102_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r13_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r195_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r188_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r145_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r130_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r50_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r11_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r103_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r14_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r161_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r70_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r156_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r196_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r39_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r167_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r41_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r98_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r158_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r86_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r37_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r134_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r94_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r128_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r111_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r65_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r88_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r30_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r49_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r5_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r87_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r71_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r143_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r178_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r166_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r31_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r185_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r160_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r60_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r15_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r22_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r69_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r6_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r138_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r172_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r180_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r76_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r197_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r121_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r127_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping RandomForest_r16_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r194_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r12_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r135_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r4_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTrees_r126_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r36_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r100_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r163_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping CatBoost_r198_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_r187_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r19_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r95_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_r34_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBM_r42_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r1_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_r89_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -16.63s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 13\n",
            "Ensemble weights: \n",
            "[0.         0.         0.92307692 0.07692308]\n",
            "\t4.56s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.923, 'LightGBM_BAG_L2': 0.077}\n",
            "\t0.9669\t = Validation score   (roc_auc)\n",
            "\t13.01s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "\t604.2\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 2606.86s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 604.2 rows/s (73818 batch size)\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/learner.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/predictor.pkl\n",
            "Saving /content/IEEEfraud/AutoGluonModels/version.txt with contents \"1.1.1\"\n",
            "Saving /content/IEEEfraud/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/IEEEfraud/AutoGluonModels/\")\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                 model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3   0.966877     roc_auc     122.396760  2442.583596                0.242915          13.010004            3       True          6\n",
            "1    LightGBMXT_BAG_L2   0.966789     roc_auc     119.619341  2315.572231               38.092619         706.800355            2       True          4\n",
            "2      LightGBM_BAG_L2   0.961981     roc_auc      84.061226  1722.773237                2.534504         114.001361            2       True          5\n",
            "3    LightGBMXT_BAG_L1   0.961952     roc_auc      73.795965  1380.500571               73.795965        1380.500571            1       True          1\n",
            "4  WeightedEnsemble_L2   0.961952     roc_auc      73.925431  1387.307568                0.129466           6.806998            2       True          3\n",
            "5      LightGBM_BAG_L1   0.928184     roc_auc       7.730757   228.271306                7.730757         228.271306            1       True          2\n",
            "Number of models trained: 6\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "Plot summary of models saved to file: /content/IEEEfraud/AutoGluonModels/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_identity = pd.read_csv(directory+'test_identity.csv')\n",
        "test_transaction = pd.read_csv(directory+'test_transaction.csv')\n",
        "test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n",
        "\n",
        "# Check for missing columns in test_data compared to train_data\n",
        "missing_cols = set(train_data.columns) - set(test_data.columns)\n",
        "\n",
        "# If there are missing columns, add them to test_data with default values\n",
        "if missing_cols:\n",
        "    for col in missing_cols:\n",
        "        test_data[col] = 0  # or any other suitable default value\n",
        "\n",
        "y_predproba = predictor.predict_proba(test_data)\n",
        "y_predproba.head(5)  # some example predicted fraud-probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "G235WU7Pp5ra",
        "outputId": "72bffa2c-e7c9-4d25-f67c-13a2ffdbb327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0  0.937980  0.062020\n",
              "1  0.997044  0.002956\n",
              "2  0.997271  0.002729\n",
              "3  0.996911  0.003089\n",
              "4  0.988016  0.011984"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75a67cad-4375-4782-b6b8-820695af993e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.937980</td>\n",
              "      <td>0.062020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.997044</td>\n",
              "      <td>0.002956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.997271</td>\n",
              "      <td>0.002729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.996911</td>\n",
              "      <td>0.003089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.988016</td>\n",
              "      <td>0.011984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75a67cad-4375-4782-b6b8-820695af993e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75a67cad-4375-4782-b6b8-820695af993e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75a67cad-4375-4782-b6b8-820695af993e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d6b096b2-7611-4d07-ac2e-cf686bbd5423\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6b096b2-7611-4d07-ac2e-cf686bbd5423')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d6b096b2-7611-4d07-ac2e-cf686bbd5423 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y_predproba"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.positive_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX8tYFkivF_v",
        "outputId": "99bd2946-2b5f-4e5b-b1dc-00c192cbafe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.class_labels # classes in this list correspond to columns of predict_proba() output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaSYZk53vKje",
        "outputId": "ba9bf2f5-0460-4f2c-82ce-b65be597029b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predproba = predictor.predict_proba(test_data, as_multiclass=False)\n",
        "y_predproba.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "50Il7mXvvOnF",
        "outputId": "6b281c09-249e-4601-850d-0612a6b3ccfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/IEEEfraud/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.062020\n",
              "1    0.002956\n",
              "2    0.002729\n",
              "3    0.003089\n",
              "4    0.011984\n",
              "Name: isFraud, dtype: float32"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.062020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float32</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv(directory+'sample_submission.csv')\n",
        "submission['isFraud'] = y_predproba\n",
        "submission.head()\n",
        "submission.to_csv(directory+'my_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "y79MCRlmvXOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}